{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9943897,"sourceType":"datasetVersion","datasetId":6114322},{"sourceId":9954457,"sourceType":"datasetVersion","datasetId":6122161},{"sourceId":9960652,"sourceType":"datasetVersion","datasetId":6126662},{"sourceId":9960763,"sourceType":"datasetVersion","datasetId":6126749}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install nltk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T05:36:02.276126Z","iopub.execute_input":"2024-11-24T05:36:02.276455Z","iopub.status.idle":"2024-11-24T05:36:11.683897Z","shell.execute_reply.started":"2024-11-24T05:36:02.276424Z","shell.execute_reply":"2024-11-24T05:36:11.682862Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport logging\nimport json\nimport numpy as np\nimport faiss\nimport re\nimport pdfplumber\nimport torch\nimport whisper\nimport wave\nimport tempfile\nimport speech_recognition as sr\nfrom sentence_transformers import SentenceTransformer\nfrom typing import List, Dict, Any, Optional, Tuple\nfrom nltk.tokenize import sent_tokenize\nimport nltk\nimport traceback\nnltk.download('punkt_tab')\nnltk.download('wordnet')\nnltk.download('omw-1.4')\n\ndef initialize_nltk():\n    \"\"\"Initialize required NLTK resources\"\"\"\n    resources = ['punkt']\n    for resource in resources:\n        try:\n            nltk.data.find(f'tokenizers/{resource}')\n        except LookupError:\n            try:\n                nltk.download(resource, quiet=True)\n            except Exception as e:\n                raise RuntimeError(f\"Failed to download NLTK resource '{resource}': {str(e)}\")\n\n# Call initialization at module level\ninitialize_nltk()\n\nclass ChatbotEvaluator:\n    def __init__(self, chatbot):\n        self.chatbot = chatbot\n        self.metrics = {\n            'total_queries': 0,\n            'successful_responses': 0,\n            'avg_response_length': 0,\n            'confidence_scores': [],\n            'query_types': {}\n        }\n    \n    # Rest of the ChatbotEvaluator class remains the same...\n    def evaluate_response(self, query: str, response: str) -> dict:\n        \"\"\"Evaluate chatbot response and update metrics\"\"\"\n        evaluation = {\n            'query_length': len(query.split()),\n            'response_length': len(response.split()),\n            'query_type': self._classify_query(query),\n            'confidence_score': self._calculate_confidence(query, response)\n        }\n        \n        self.metrics['total_queries'] += 1\n        self.metrics['successful_responses'] += 1 if len(response) > 10 else 0\n        self.metrics['confidence_scores'].append(evaluation['confidence_score'])\n        \n        query_type = evaluation['query_type']\n        self.metrics['query_types'][query_type] = \\\n            self.metrics['query_types'].get(query_type, 0) + 1\n        \n        return evaluation\n    \n    def _classify_query(self, query: str) -> str:\n        \"\"\"Classify the type of query\"\"\"\n        query = query.lower()\n        if '?' in query:\n            return 'question'\n        elif any(word in query for word in ['explain', 'describe', 'define', 'elaborate', 'clarify']):\n            return 'explanation'\n        elif any(word in query for word in ['how', 'why', 'what', 'when', 'where', 'who']):\n            return 'inquiry'\n        elif any(word in query for word in ['compare', 'contrast', 'difference', 'similar']):\n            return 'comparison'\n        elif any(word in query for word in ['example', 'instance', 'scenario']):\n            return 'example_request'\n        return 'general'\n    \n    def _calculate_confidence(self, query: str, response: str) -> float:\n        \"\"\"Calculate confidence score for response\"\"\"\n        query_terms = set(query.lower().split())\n        response_terms = set(response.lower().split())\n        term_overlap = len(query_terms & response_terms)\n        semantic_relevance = self.chatbot.embedding_model.encode([query, response])\n        cosine_similarity = np.dot(semantic_relevance[0], semantic_relevance[1]) / \\\n                          (np.linalg.norm(semantic_relevance[0]) * np.linalg.norm(semantic_relevance[1]))\n        \n        confidence = 0.4 * (term_overlap / len(query_terms) if query_terms else 0) + \\\n                    0.6 * cosine_similarity\n        return float(min(confidence, 1.0))\n    \n    def get_performance_report(self) -> Dict[str, Any]:\n        \"\"\"Generate performance report\"\"\"\n        return {\n            'total_queries': self.metrics['total_queries'],\n            'success_rate': self.metrics['successful_responses'] / max(1, self.metrics['total_queries']),\n            'avg_confidence': np.mean(self.metrics['confidence_scores']) if self.metrics['confidence_scores'] else 0,\n            'query_type_distribution': self.metrics['query_types']\n        }\n\n\n\n            \nclass DisciplinaryRuleBookChatbot:\n    def __init__(\n        self, \n        pdf_path: str, \n        config_path: Optional[str] = None,\n        debug: bool = False,\n        enable_voice: bool = True,\n        whisper_model: str = \"base\"\n    ):\n        # Initialize logger\n        self.logger = logging.getLogger(__name__)\n        if debug:\n            logging.basicConfig(level=logging.DEBUG)\n        else:\n            logging.basicConfig(level=logging.INFO)\n            \n        try:\n            # Store initialization parameters\n            self.pdf_path = pdf_path\n            self.debug = debug\n            self.enable_voice = enable_voice\n            \n            # Load configuration\n            default_config = {\n                'embedding_model': 'all-mpnet-base-v2',\n                'confidence_threshold': 0.3,\n                'top_k_results': 3,  # Increased for more comprehensive responses\n                'min_section_length': 20,\n                'max_response_sentences': 10,  # Increased for longer responses\n                'min_response_sentences': 5,   # Minimum sentences in response\n                'context_window': 5,          # Increased context window\n                'table_extraction': True,\n                'response_instructions': [\n                    \"Provide comprehensive explanations with examples when possible\",\n                    \"Include relevant context and background information\",\n                    \"Elaborate on key points with supporting details\",\n                    \"Connect related concepts and policies\",\n                    \"Ensure response addresses all aspects of the query\",\n                    \"Include relevant policy references\",\n                    \"Maintain professional tone\",\n                    \"Use concrete examples where appropriate\"\n                ],\n                'response_templates': {\n                    'policy': \"According to section {section}: {content}\",\n                    'clarification': \"To elaborate on this topic: {content}\",\n                    'example': \"To illustrate this point: {content}\",\n                    'reference': \"For more detailed information, please refer to {section}.\"\n                },\n                'section_patterns': [\n                    r'\\n\\d+[\\s\\.]+[A-Za-z][^\\n]+\\n',\n                    r'\\n\\d+\\.\\d+[\\s\\.]+[A-Za-z][^\\n]+\\n',\n                    r'\\n\\d+\\.\\d+\\.\\d+[\\s\\.]+[A-Za-z][^\\n]+\\n',\n                    r'\\n[A-Z][^\\n]+\\n',\n                    r'\\n[IVX]+\\.?\\s+[A-Z][^\\n]+\\n'\n                ],\n                'transition_phrases': [\n                    \"Furthermore, \",\n                    \"Additionally, \",\n                    \"Moreover, \",\n                    \"In relation to this, \",\n                    \"It's important to note that \",\n                    \"Building on this point, \",\n                    \"In this context, \",\n                    \"To provide more detail, \",\n                    \"Specifically, \",\n                    \"On a related note, \"\n                ]\n            }\n            \n            # Load custom config if provided\n            if config_path and os.path.exists(config_path):\n                with open(config_path, 'r') as f:\n                    custom_config = json.load(f)\n                    default_config.update(custom_config)\n            \n            self.config = default_config\n            \n            # Initialize embedding model\n            self.logger.info(f\"Loading embedding model: {self.config['embedding_model']}\")\n            self.embedding_model = SentenceTransformer(self.config['embedding_model'])\n            \n            # Initialize voice transcription if enabled\n            self.whisper = None\n            if enable_voice:\n                self.logger.info(f\"Initializing Whisper with model: {whisper_model}\")\n                self.whisper = WhisperTranscriber(model_size=whisper_model, debug=debug)\n            \n            # Extract and process PDF content\n            self.logger.info(\"Extracting text from PDF\")\n            raw_text = self._extract_raw_pdf_text()\n            \n            # Split into sections\n            self.logger.info(\"Splitting text into sections\")\n            self.policy_sections = self._split_into_sections(raw_text)\n            \n            if not self.policy_sections:\n                raise ValueError(\"No valid sections found in the PDF\")\n            \n            # Generate embeddings\n            self.logger.info(\"Generating section embeddings\")\n            self.section_embeddings = self._generate_embeddings()\n            \n            # Create FAISS index\n            self.logger.info(\"Creating FAISS index\")\n            self.index = self._create_faiss_index()\n            \n            # Initialize evaluator\n            self.evaluator = ChatbotEvaluator(self)\n            \n            self.logger.info(\"Initialization complete\")\n            \n        except Exception as e:\n            self.logger.error(f\"Initialization failed: {str(e)}\")\n            raise\n\n    def _extract_raw_pdf_text(self) -> str:\n        \"\"\"Extract text from PDF document with enhanced cleaning and formatting\"\"\"\n        try:\n            text = \"\"\n            with pdfplumber.open(self.pdf_path) as pdf:\n                for page in pdf.pages:\n                    # Extract main text\n                    page_text = page.extract_text() or \"\"\n                    \n                    # Clean up dots from table of contents and page numbers\n                    page_text = re.sub(r'\\.{2,}.*?(\\d+)$', '', page_text, flags=re.MULTILINE)\n                    \n                    # Remove standalone page numbers\n                    page_text = re.sub(r'^\\s*\\d+\\s*$', '', page_text, flags=re.MULTILINE)\n                    \n                    # Clean up extra whitespace while preserving paragraph breaks\n                    page_text = re.sub(r'\\s+', ' ', page_text)\n                    page_text = re.sub(r'\\s*\\n\\s*', '\\n', page_text)\n                    \n                    # Extract tables if enabled\n                    if self.config['table_extraction']:\n                        tables = page.extract_tables()\n                        for table in tables:\n                            if table and any(any(cell for cell in row) for row in table):\n                                table_text = self._format_table(table)\n                                if table_text:\n                                    page_text += f\"\\n{table_text}\\n\"\n                    \n                    text += page_text + \"\\n\"\n            \n            # Final cleaning\n            text = self._clean_extracted_text(text)\n            return text.strip()\n            \n        except Exception as e:\n            self.logger.error(f\"PDF text extraction failed: {str(e)}\")\n            raise\n    def _clean_extracted_text(self, text: str) -> str:\n        \"\"\"Clean and format extracted text\"\"\"\n        # Remove table of contents formatting\n        text = re.sub(r'(\\d+\\..*?)\\.{2,}\\s*\\d+', r'\\1', text)\n        \n        # Fix section headers\n        text = re.sub(r'(\\d+\\.\\d*)\\s*([A-Z])', r'\\n\\1 \\2', text)\n        \n        # Remove duplicate section headers\n        lines = text.split('\\n')\n        unique_lines = []\n        seen_headers = set()\n        \n        for line in lines:\n            # Check if line is a section header\n            header_match = re.match(r'^\\s*(\\d+\\.\\d*\\s+[A-Z].*?)$', line)\n            if header_match:\n                header = header_match.group(1)\n                if header not in seen_headers:\n                    seen_headers.add(header)\n                    unique_lines.append(line)\n            else:\n                unique_lines.append(line)\n        \n        text = '\\n'.join(unique_lines)\n        \n        # Remove empty lines and normalize spacing\n        text = '\\n'.join(line.strip() for line in text.split('\\n') if line.strip())\n        \n        return text\n\n    def _format_table(self, table: List[List[str]]) -> str:\n        \"\"\"Format extracted table as readable text\"\"\"\n        if not table or not any(table):\n            return \"\"\n        \n        formatted_rows = []\n        # Clean and format header\n        if table[0]:\n            headers = [str(cell).strip() if cell else \"\" for cell in table[0]]\n            formatted_rows.append(\" | \".join(headers))\n            formatted_rows.append(\"-\" * len(formatted_rows[0]))  # Add separator\n        \n        # Format data rows\n        for row in table[1:]:\n            cleaned_row = [str(cell).strip() if cell else \"\" for cell in row]\n            if any(cleaned_row):  # Only add non-empty rows\n                formatted_rows.append(\" | \".join(cleaned_row))\n        \n        return \"\\n\".join(formatted_rows)\n\n    def _split_into_sections(self, text: str) -> List[Dict[str, str]]:\n        \"\"\"Split text into sections with improved structure\"\"\"\n        sections = []\n        current_section = {'title': '', 'content': []}\n        lines = text.split('\\n')\n        \n        for line in lines:\n            # Check if line is a section header\n            header_match = re.match(r'^\\s*(\\d+\\.?\\d*)\\s+([A-Z].*?)$', line)\n            \n            if header_match:\n                # Save previous section if it exists\n                if current_section['content']:\n                    sections.append({\n                        'title': current_section['title'],\n                        'content': '\\n'.join(current_section['content'])\n                    })\n                \n                # Start new section\n                current_section = {\n                    'title': line.strip(),\n                    'content': []\n                }\n            elif line.strip():\n                # Add non-empty lines to current section\n                current_section['content'].append(line.strip())\n        \n        # Add last section\n        if current_section['content']:\n            sections.append({\n                'title': current_section['title'],\n                'content': '\\n'.join(current_section['content'])\n            })\n        \n        return sections\n\n    def _generate_embeddings(self) -> np.ndarray:\n        \"\"\"Generate embeddings for text sections\"\"\"\n        try:\n            return self.embedding_model.encode(self.policy_sections, show_progress_bar=True)\n        except Exception as e:\n            self.logger.error(f\"Embedding generation failed: {str(e)}\")\n            raise\n\n    def _create_faiss_index(self) -> faiss.IndexFlatL2:\n        \"\"\"Create FAISS index for efficient similarity search\"\"\"\n        try:\n            dimension = self.section_embeddings.shape[1]\n            index = faiss.IndexFlatL2(dimension)\n            index.add(self.section_embeddings)\n            return index\n        except Exception as e:\n            self.logger.error(f\"FAISS index creation failed: {str(e)}\")\n            raise\n\n    def find_relevant_sections(self, query: str) -> List[Tuple[int, str]]:\n        \"\"\"Find relevant sections for a query with improved relevance scoring\"\"\"\n        try:\n            # Generate query embedding\n            query_embedding = self.embedding_model.encode([query])\n            \n            # Search index with increased k for more comprehensive results\n            k = min(self.config['top_k_results'], len(self.policy_sections))\n            distances, indices = self.index.search(query_embedding, k)\n            \n            # Calculate confidence scores and filter results\n            relevant_sections = []\n            for distance, idx in zip(distances[0], indices[0]):\n                confidence = 1 / (1 + distance)  # Convert distance to similarity score\n                if confidence >= self.config['confidence_threshold']:\n                    relevant_sections.append((idx, self.policy_sections[idx]))\n            \n            return relevant_sections\n        \n        except Exception as e:\n            self.logger.error(f\"Section search failed: {str(e)}\")\n            raise\n\n    def generate_response(self, query: str) -> str:\n        \"\"\"Generate response with improved content handling\"\"\"\n        try:\n            relevant_sections = self.find_relevant_sections(query)\n            \n            if not relevant_sections:\n                return (\"I couldn't find any specific information about attendance rules. \"\n                       \"Please try rephrasing your question or specify which type of attendance \"\n                       \"rules you're interested in (e.g., class attendance, employee attendance, etc.).\")\n            \n            # Build response with proper structure\n            response_parts = []\n            \n            # Add introduction\n            query_type = self.evaluator._classify_query(query)\n            response_parts.append(self._get_introduction(query_type))\n            \n            # Process each relevant section\n            for idx, section in relevant_sections:\n                if isinstance(section, dict):\n                    title = section.get('title', '')\n                    content = section.get('content', '')\n                else:\n                    # Handle old format sections\n                    title_match = re.match(r'^([\\d\\.]+\\s+[A-Z][^\\n]+)', section)\n                    title = title_match.group(1) if title_match else \"\"\n                    content = section[len(title):] if title else section\n                \n                # Add section title if it exists\n                if title:\n                    response_parts.append(f\"\\n{title}\")\n                \n                # Add cleaned content\n                if content:\n                    content = re.sub(r'\\s+', ' ', content).strip()\n                    response_parts.append(content)\n            \n            # Combine parts with proper spacing\n            response = '\\n'.join(part for part in response_parts if part.strip())\n            \n            # Add key points\n            key_sentences = self._extract_key_points(response)\n            if key_sentences:\n                response += \"\\n\\nKey points:\\n\" + \"\\n\".join(f\"• {point}\" for point in key_sentences)\n            \n            # Add reference footer\n            if relevant_sections:\n                section_refs = [f\"Section {i+1}\" for i, _ in relevant_sections[:3]]\n                response += f\"\\n\\nFor more detailed information, please refer to: {', '.join(section_refs)}.\"\n            \n            return response\n            \n        except Exception as e:\n            self.logger.error(f\"Response generation failed: {str(e)}\")\n            raise\n\n    def _get_introduction(self, query_type: str) -> str:\n        \"\"\"Get appropriate introduction based on query type\"\"\"\n        introductions = {\n            'explanation': \"Here's a detailed explanation of the attendance rules and policies. \",\n            'example_request': \"Let me provide specific examples of the attendance requirements. \",\n            'comparison': \"Let me outline the key attendance policies and requirements. \",\n            'inquiry': \"I'll address your question about attendance policies in detail. \",\n            'general': \"Here are the important attendance rules and regulations. \"\n        }\n        return introductions.get(query_type, introductions['general'])\n    def _extract_key_points(self, text: str) -> List[str]:\n        \"\"\"Extract key points from the response text\"\"\"\n        sentences = sent_tokenize(text)\n        key_points = []\n        \n        # Look for important sentences containing key information\n        for sentence in sentences:\n            # Prioritize sentences with important keywords\n            if any(keyword in sentence.lower() for keyword in ['must', 'required', 'mandatory', 'important', 'essential']):\n                key_points.append(sentence)\n                \n            # Add sentences that appear to be rules or requirements\n            if re.search(r'^\\d+\\.|\\bshall\\b|\\bmust\\b|\\bis required to\\b', sentence):\n                key_points.append(sentence)\n        \n        # Limit to 3-5 key points and remove duplicates\n        key_points = list(dict.fromkeys(key_points))[:5]\n        return key_points\n\n    def _apply_response_instructions(self, response: str, query_type: str, sections: List[Tuple[int, str]]) -> str:\n        \"\"\"Apply enhanced response instructions for more elaborate answers\"\"\"\n        try:\n            formatted_response = response\n            \n            # Add contextual introduction based on query type\n            introductions = {\n                'explanation': \"Let me provide a detailed explanation of this topic. \",\n                'example_request': \"Here's a comprehensive example with detailed context. \",\n                'comparison': \"Let me break down the key differences and similarities. \",\n                'inquiry': \"I'll address your question with comprehensive information. \",\n                'general': \"Let me provide detailed information about this topic. \"\n            }\n            \n            formatted_response = introductions.get(query_type, introductions['general']) + formatted_response\n            \n            # Enhance formatting and structure\n            paragraphs = formatted_response.split('\\n\\n')\n            enhanced_paragraphs = []\n            \n            for i, paragraph in enumerate(paragraphs):\n                if i == 0:  # First paragraph\n                    enhanced_paragraphs.append(paragraph)\n                else:  # Add transitions between paragraphs\n                    transition = self._get_transition_phrase(i, len(paragraphs))\n                    enhanced_paragraphs.append(f\"{transition} {paragraph}\")\n            \n            formatted_response = '\\n\\n'.join(enhanced_paragraphs)\n            \n            return formatted_response\n            \n        except Exception as e:\n            self.logger.error(f\"Response formatting failed: {str(e)}\")\n            return response\n\n    def _get_transition_phrase(self, position: int, total_paragraphs: int) -> str:\n        \"\"\"Get appropriate transition phrase based on paragraph position\"\"\"\n        if position == 1:\n            return \"To expand on this,\"\n        elif position == total_paragraphs - 1:\n            return \"Finally,\"\n        else:\n            transitions = self.config['transition_phrases']\n            return transitions[position % len(transitions)]\n            \n    def process_voice_query(self, duration: int = 10) -> str:\n        \"\"\"Record and transcribe voice query\"\"\"\n        if not self.whisper:\n            raise ValueError(\"Voice input is not enabled\")\n        \n        try:\n            self.logger.debug(\"Processing voice query\")\n            audio_path = self.whisper.record_audio(duration)\n            query = self.whisper.transcribe(audio_path)\n            \n            if not query:\n                raise ValueError(\"No speech detected\")\n            \n            return query\n            \n        except Exception as e:\n            self.logger.error(f\"Voice query processing failed: {str(e)}\")\n            raise\n\nclass WhisperTranscriber:\n    \"\"\"Handle audio recording and transcription using Whisper\"\"\"\n    def __init__(self, model_size: str = \"base\", debug: bool = False):\n        self.logger = logging.getLogger(__name__)\n        self.debug = debug\n        self.sample_rate = 16000\n        self.channels = 1\n        self.recognizer = sr.Recognizer()\n        \n        try:\n            if self.debug:\n                self.logger.debug(f\"Loading Whisper model: {model_size}\")\n            self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n            self.model = whisper.load_model(model_size).to(self.device)\n        except Exception as e:\n            self.logger.error(f\"Failed to initialize Whisper: {str(e)}\")\n            raise\n\n    def record_audio(self, duration: int = 10) -> str:\n        \"\"\"Record audio using speech_recognition\"\"\"\n        try:\n            temp_file = tempfile.mktemp(suffix=\".wav\")\n            \n            # Record audio using system microphone\n            with sr.Microphone() as source:\n                print(f\"Recording for {duration} seconds...\")\n                self.recognizer.adjust_for_ambient_noise(source)\n                audio = self.recognizer.record(source, duration=duration)\n                print(\"Recording complete!\")\n            \n            # Save to WAV file\n            with wave.open(temp_file, 'wb') as wf:\n                wf.setnchannels(self.channels)\n                wf.setsampwidth(2)  # 2 bytes per sample\n                wf.setframerate(self.sample_rate)\n                wf.writeframes(audio.get_wav_data())\n            \n            return temp_file\n        except Exception as e:\n            self.logger.error(f\"Audio recording failed: {str(e)}\")\n            raise\n\n    def transcribe(self, audio_path: str) -> str:\n        \"\"\"Transcribe audio file using Whisper\"\"\"\n        try:\n            result = self.model.transcribe(audio_path)\n            return result[\"text\"].strip()\n        except Exception as e:\n            self.logger.error(f\"Transcription failed: {str(e)}\")\n            raise\n        finally:\n            if os.path.exists(audio_path):\n                os.remove(audio_path)\n\ndef main():\n    try:\n        # Configurable PDF path\n        pdf_path = input(\"Enter the full path to the PDF manual: \").strip()\n        \n        if not os.path.exists(pdf_path):\n            print(f\"Error: PDF file not found at {pdf_path}\")\n            return\n        \n        # Enable debug mode with user input\n        debug_mode = input(\"Enable debug mode? (yes/no): \").lower().strip() == 'yes'\n        \n        # Configure voice input\n        enable_voice = input(\"Enable voice input? (yes/no): \").lower().strip() == 'yes'\n        whisper_model = \"base\"\n        if enable_voice:\n            print(\"\\nAvailable Whisper models: tiny, base, small, medium, large\")\n            whisper_model = input(\"Select Whisper model size (default: base): \").strip() or \"base\"\n        \n        print(\"\\nInitializing chatbot...\")\n        \n        # Initialize chatbot\n        chatbot = DisciplinaryRuleBookChatbot(\n            pdf_path=pdf_path,\n            debug=debug_mode,\n            enable_voice=enable_voice,\n            whisper_model=whisper_model\n        )\n        print(f\"\\nChatbot initialized successfully!\")\n        \n        # Interactive chat loop\n        while True:\n            try:\n                input_mode = input(\"\\nChoose input mode (text/voice/quit/report): \").strip().lower()\n                \n                if input_mode == 'quit':\n                    break\n                \n                if input_mode == 'report':\n                    # Generate and display performance report\n                    report = chatbot.evaluator.get_performance_report()\n                    print(\"\\nPerformance Report:\")\n                    print(f\"Total Queries: {report['total_queries']}\")\n                    print(f\"Success Rate: {report['success_rate']:.2%}\")\n                    print(f\"Average Confidence: {report['avg_confidence']:.2%}\")\n                    print(\"\\nQuery Type Distribution:\")\n                    for qtype, count in report['query_type_distribution'].items():\n                        print(f\"  {qtype}: {count}\")\n                    continue\n                \n                if input_mode == 'voice':\n                    if not chatbot.whisper:\n                        print(\"Voice input is not available. Please install required dependencies.\")\n                        continue\n                    try:\n                        print(\"\\nListening... (Press Ctrl+C to stop)\")\n                        query = chatbot.process_voice_query()\n                        print(f\"\\nTranscribed Query: {query}\")\n                    except KeyboardInterrupt:\n                        print(\"\\nRecording stopped.\")\n                        continue\n                    except Exception as e:\n                        print(f\"\\nVoice input error: {str(e)}\")\n                        continue\n                elif input_mode == 'text':\n                    query = input(\"\\nEnter your query: \").strip()\n                else:\n                    print(\"Invalid input mode. Please choose 'text', 'voice', 'report', or 'quit'.\")\n                    continue\n                \n                if not query:\n                    print(\"Please provide a valid query.\")\n                    continue\n                \n                # Generate and display response with error handling\n                try:\n                    response = chatbot.generate_response(query)\n                    print(f\"\\nResponse: {response}\")\n                except Exception as e:\n                    print(f\"\\nError generating response: {str(e)}\")\n                    if debug_mode:\n                        print(f\"Stack trace: {traceback.format_exc()}\")\n                \n            except KeyboardInterrupt:\n                print(\"\\nOperation cancelled by user.\")\n            except Exception as e:\n                print(f\"\\nError processing input: {str(e)}\")\n                if debug_mode:\n                    print(f\"Stack trace: {traceback.format_exc()}\")\n\n    except KeyboardInterrupt:\n        print(\"\\nExiting...\")\n    except Exception as e:\n        print(f\"\\nFatal error: {str(e)}\")\n        if debug_mode:\n            print(f\"Stack trace: {traceback.format_exc()}\")\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T06:11:56.557746Z","iopub.execute_input":"2024-11-24T06:11:56.558366Z","iopub.status.idle":"2024-11-24T06:14:54.264300Z","shell.execute_reply.started":"2024-11-24T06:11:56.558333Z","shell.execute_reply":"2024-11-24T06:14:54.263515Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n[nltk_data]   Package punkt_tab is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package omw-1.4 to /usr/share/nltk_data...\n[nltk_data]   Package omw-1.4 is already up-to-date!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Enter the full path to the PDF manual:  /kaggle/input/iitgmanual/UGManual.pdf\nEnable debug mode? (yes/no):  yes\nEnable voice input? (yes/no):  yes\n"},{"name":"stdout","text":"\nAvailable Whisper models: tiny, base, small, medium, large\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Select Whisper model size (default: base):  \n"},{"name":"stdout","text":"\nInitializing chatbot...\n","output_type":"stream"},{"name":"stderr","text":"100%|████████████████████████████████████████| 139M/139M [00:01<00:00, 116MiB/s]\n/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(fp, map_location=device)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ea578fafaf984ab4b7045c4ff0b680e9"}},"metadata":{}},{"name":"stdout","text":"\nChatbot initialized successfully!\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  voice\n"},{"name":"stdout","text":"\nListening... (Press Ctrl+C to stop)\n\nVoice input error: Could not find PyAudio; check installation\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  text\n\nEnter your query:  what are the misbehavings of a student?\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5a9a93b1c2204777a57ca3a2033d5c15"}},"metadata":{}},{"name":"stdout","text":"\nResponse: Here are the important attendance rules and regulations. \n\n4.6 Theevaluationforself-studywillbedoneinasimilarwayasisdoneforanormal semestercourse. Academicstandardsmustberigorouslymaintainedintheself- study mode. The instructor must supervise the student from time to time apart from an examination at the end of the course.\n5.\n\n3.11 Students on academic probation are mandatorily put on a slow track of learn- ing. These students may register for up to 12 credits only with priority given to 1PS:ThecreditsearnedintheSummerterm(seeSection3.1)isnotconsidered\nCriteria | Maximum Academic Overload ------------------------------------ CPI < 5 | No overloading allowed 5 ≤ CPI ≤ 7 | Overload up to 4 credits CPI ≥ 7 | Overload up to 8 credits availablebacklogcourses. TheP,Q,RandS parametersforthestudentswillbe adjusted accordingly. 7.\n\n2.2 Student Affairs Office The student affairs office (SAO) is headed by Dean of Student Affairs (Dean (SA)) or the Faculty-in-Charge. It is primarily responsible for ensuring the well-being of students on campusthroughplanning,coordinatingandexecutingpertinentactivities. Inconsultation with various faculty advisors and wardens, SAO undertakes following responsibilities: • Coordinating the extra and co-curricular activities for students in three broad domains: Technical, Cultural and Sports (in close consultation with respective Faculty Advisors). • Ensuring the maintenance of hostel premises including the quality of catering services in the hostel mess (with the help of mess and hostel council including student members). • Coordinating the allotment of hostel rooms for all the eligible student (through hall office in consultation with wardens).\n• Coordinationoffinancialactivitiesofstudentssuchascollectionoffeesincluding mess charges, processing of internal and external scholarships, insurance etc.. • Ensuring the observation of hostel rules and code of conduct by the residents and issuing necessary penalty in case of any deviation (through hall office in consultation with wardens). • Ensuringthementalwell-beingofstudentsthroughpreventivewellnessactivities as well as counselling (through Wellness and Counselling Cell). • Conducting the yearly elections for the Students’ Council. • Coordinating the Alumni Cell activities (through members of the alumni cell).\n\nKey points:\n• Here are the important attendance rules and regulations.\n• 4.6 Theevaluationforself-studywillbedoneinasimilarwayasisdoneforanormal semestercourse.\n• Academicstandardsmustberigorouslymaintainedintheself- study mode.\n• The instructor must supervise the student from time to time apart from an examination at the end of the course.\n• 5.\n\nFor more detailed information, please refer to: Section 15, Section 21, Section 4.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  report\n"},{"name":"stdout","text":"\nPerformance Report:\nTotal Queries: 0\nSuccess Rate: 0.00%\nAverage Confidence: 0.00%\n\nQuery Type Distribution:\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  what are the misbehavings of a student?\n"},{"name":"stdout","text":"Invalid input mode. Please choose 'text', 'voice', 'report', or 'quit'.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  text\n\nEnter your query:  suspension rules\n"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ad30c10dbdd407c95e5d573a6cb8186"}},"metadata":{}},{"name":"stdout","text":"\nResponse: Here are the important attendance rules and regulations. \n\n3.11 Students on academic probation are mandatorily put on a slow track of learn- ing. These students may register for up to 12 credits only with priority given to 1PS:ThecreditsearnedintheSummerterm(seeSection3.1)isnotconsidered\nCriteria | Maximum Academic Overload ------------------------------------ CPI < 5 | No overloading allowed 5 ≤ CPI ≤ 7 | Overload up to 4 credits CPI ≥ 7 | Overload up to 8 credits availablebacklogcourses. TheP,Q,RandS parametersforthestudentswillbe adjusted accordingly. 7.\n\n3.13 Students who are found to be unable to cope with even the slow track of learn- ing may become eligible for termination from the program. If a student already onAcademicProbation/Warningsatisfieseitherorbothoftheabove-mentioned conditionsattheendofthecurrentsemester,thentheAcademicProgramofthe student will be terminated. ConsulttheGuidelinesformultipleentryandexitformoreinformationontheexitpolicies of the institute. MaximumPeriodforCompletionofProgram Astudentisrequiredtofulfiltherequire- ments for their respective degree within the maximum period specified for the program, includingwithdrawalinexceptionalcircumstances,failingwhichtheircasewillbereferred totheSenatefordismissal. Ifastudentfailstocompletetheiracademic. Programwithin 12semesters(6years),theiracademicprogramwillbeautomaticallyterminated. However, if there are valid reasons, an appeal can be submitted to the Chair, senate for reinstate- ment of their academic program. If the appeal is approved, the student will be required to pay appropriate fees as mentioned in the institute’s fee structure. Appeal for Reinstatement A student whose program is terminated may appeal to the Chairman, Senate, for reinstatement in the program. In case of termination due to inad- equate academic performance, the student should clearly explain the reason(s) for poor performance, including how those reason(s) will not adversely affect her/his performance in future. The Senate shall take a final decision after considering all available inputs. A studentmayre-appealevenafterapreviousappealhasbeenrejected. However,theSen- atemaynotentertainanyre-appealforreviewunlesssubstantialadditionalinformationis brought to its notice. No-Fail Policy for First Year B.Tech. Students One problem that faces every one of all the IITs is the unhealthy level of stress felt by many students, often leading to severe\npsychiatric disorders. As new students enters an IIT, the students perceives an intense competitioninanenvironmententirelynewtohis/herexperience. Further,his/herperfor- manceintheveryfirstsemester,ifpoor,oftenleadsthestudenttoidentifyhimself/herself asadeficientstudent,andthisearlyidentificationofoneselfmayleadtoasenseof‘giving up’ for the rest of the students stay in the institute. In view of the above, to relieve the stress of the students, a No-Fail policy has been ap- proved by the senate of IIT Goa. This No-Fail policy will not reduce any Academic credit requirement for obtaining the degree. It will only relieve the stress of the students. The following are the salient features of the no-fail policy: 7.\n\n2.4 The leave of absence in the summer term shall correspondingly be five working days (medical) and three working days (others), i.e., eight working days total.\n6.\n\nKey points:\n• Here are the important attendance rules and regulations.\n• 3.11 Students on academic probation are mandatorily put on a slow track of learn- ing.\n• 7.\n• 3.13 Students who are found to be unable to cope with even the slow track of learn- ing may become eligible for termination from the program.\n• MaximumPeriodforCompletionofProgram Astudentisrequiredtofulfiltherequire- ments for their respective degree within the maximum period specified for the program, includingwithdrawalinexceptionalcircumstances,failingwhichtheircasewillbereferred totheSenatefordismissal.\n\nFor more detailed information, please refer to: Section 21, Section 22, Section 16.\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nChoose input mode (text/voice/quit/report):  quit\n"}],"execution_count":33}]}